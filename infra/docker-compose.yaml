version: '3'
services:
  zookeeper:
    image: confluentinc/cp-zookeeper:latest
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
    healthcheck:
      test: ["CMD", "nc", "-z", "localhost", "2181"]
      interval: 5s
      timeout: 10s
      retries: 5

  kafka:
    image: confluentinc/cp-kafka:latest
    depends_on:
      zookeeper:
        condition: service_healthy
    ports:
      - "9092:9092"
      - "9999:9999"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_JMX_OPTS: "-Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false -Djava.rmi.server.hostname=kafka -Dcom.sun.management.jmxremote.rmi.port=9999"
      KAFKA_JMX_HOSTNAME: kafka
      KAFKA_JMX_PORT: 9999
    healthcheck:
      test: ["CMD", "kafka-topics", "--bootstrap-server", "localhost:9092", "--list"]
      interval: 10s
      timeout: 5s
      retries: 5

  kafka-exporter:
    image: bitnami/kafka-exporter:latest
    depends_on:
      kafka:
        condition: service_healthy
    ports:
      - "9308:9308"
    command:
      - --kafka.server=kafka:9092

  mysql:
    image: mysql:latest
    restart: always
    environment:
      MYSQL_ROOT_PASSWORD: root
      MYSQL_DATABASE: cdp
      MYSQL_USER: user
      MYSQL_PASSWORD: password
    ports:
      - "3306:3306"

  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.5.3
    environment:
      discovery.type: 'single-node'
      xpack.security.enabled: 'false'  
      xpack.security.http.ssl.enabled: 'false'
      xpack.security.transport.ssl.enabled: 'false'
      network.host: '0.0.0.0'
      transport.host: '0.0.0.0'
    ports:
      - "9200:9200"

  elasticsearch_exporter:
      image: quay.io/prometheuscommunity/elasticsearch-exporter:latest
      command:
      - '--es.uri=http://elasticsearch:9200'
      - '--es.shards'
      - '--es.indices'
      restart: always
      ports:
      - "9114:9114"

  kibana:
    image: docker.elastic.co/kibana/kibana:8.5.3
    depends_on:
      - elasticsearch
    ports:
      - "5601:5601"

  producer:
    depends_on:
      kafka:
        condition: service_healthy
    build: 
      context: ../
      dockerfile: Dockerfile
    ports:
      - "1000:1000"
    environment:
      PROMETHEUS_MULTIPROC_DIR: '/tmp/prometheus'
    volumes:
      - shared_metrics:/tmp/prometheus
    container_name: producer_fake
    command: ["producer"]

  consumer:
    depends_on:
      kafka:
        condition: service_healthy
    build: 
      context: ../
      dockerfile: Dockerfile
    container_name: consumer_fake
    ports:
      - "1001:1001"
    environment:
      PROMETHEUS_MULTIPROC_DIR: '/tmp/prometheus'
    volumes:
      - shared_metrics:/tmp/prometheus
    command: ["consumer"]
  
  api:
    depends_on:
      kafka:
        condition: service_healthy
    build: 
      context: ../
      dockerfile: Dockerfile
    ports:
      - "8000:8000"
      - "1002:1002"
    environment:
      PROMETHEUS_MULTIPROC_DIR: '/tmp/prometheus'
    volumes:
      - shared_metrics:/tmp/prometheus
    container_name: api_fake
    command: ["api"]
  
  prometheus:
    image: prom/prometheus
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml
    ports:
      - "9090:9090"

volumes:
  shared_metrics: